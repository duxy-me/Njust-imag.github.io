<!DOCTYPE html><html lang="en"><head><meta name="generator" content="React Static"/><meta charSet="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5, shrink-to-fit=no"/><link rel="preload" as="script" href="/templates/styles.e9e5bf98.js"/><link rel="preload" as="script" href="/templates/vendors~main.8ca25124.js"/><link rel="preload" as="script" href="/main.7753e46a.js"/><link rel="preload" as="style" href="/styles.92cee3d5.css"/><link rel="stylesheet" href="/styles.92cee3d5.css"/></head><body><div id="root"><div style="outline:none" tabindex="-1"><div class="App"><div class="jss2"><div class="jss3"><div class="jss4"><div class="content"><div><h3 class="MuiTypography-root MuiTypography-h3 MuiTypography-alignCenter" style="color:#57247b;height:80%">南京理工大学智能媒体分析实验室</h3></div><div><p class="MuiTypography-root MuiTypography-body1 MuiTypography-gutterBottom" style="color:#666666;margin-bottom:25px">Intelligent Media Analysis Group (IMAG), School of Computer Science, Nanjing University of Science and Technology</p></div></div></div></div><div class="jss6"><header class="MuiPaper-root MuiAppBar-root MuiAppBar-positionStatic MuiAppBar-colorPrimary jss9 MuiPaper-elevation4"><div class="MuiToolbar-root MuiToolbar-regular MuiToolbar-gutters"><div class="jss11"><div class="jss13"><div style="background-color:white"><a style="color:#57247b;padding-left:20px;padding-right:20px;line-height:64px;display:block" href="/">HOME</a></div><div style="background-color:"><a style="color:white;padding-left:20px;padding-right:20px;line-height:64px;display:block" href="/people">PEOPLE</a></div><div style="background-color:"><a style="color:white;padding-left:20px;padding-right:20px;line-height:64px;display:block" href="/news">NEWS</a></div><div style="background-color:"><a style="color:white;padding-left:20px;padding-right:20px;line-height:64px;display:block" href="/publication">PUBLICATIONS</a></div><div style="background-color:"><a style="color:white;padding-left:20px;padding-right:20px;line-height:64px;display:block" href="/competition">COMPETITIONS</a></div><div style="background-color:"><a style="color:white;padding-left:20px;padding-right:20px;line-height:64px;display:block" href="/grants">GRANTS</a></div><div style="background-color:"><a style="color:white;padding-left:20px;padding-right:20px;line-height:64px;display:block" href="/patent">PATENTS</a></div><div style="background-color:"><a style="color:white;padding-left:20px;padding-right:20px;line-height:64px;display:block" href="/honor">HONOR</a></div><div style="background-color:"><a style="color:white;padding-left:20px;padding-right:20px;line-height:64px;display:block" href="/resource">RESOURCE</a></div><div style="background-color:"><a style="color:white;padding-left:20px;padding-right:20px;line-height:64px;display:block" href="/contact">CONTACT</a></div></div></div></div></header></div><div class="jss5"><div style="outline:none" tabindex="-1"><div class="jss16"><h1 class="MuiTypography-root MuiTypography-h5 MuiTypography-alignCenter" style="padding-bottom:20px;padding-top:20px">项欣光</h1><div class="jss17"><div class="jss24"><span class=" lazy-load-image-background blur" style="color:transparent;display:inline-block;height:240px;width:200px"><span class="" style="display:inline-block;width:200px;height:240px"></span></span></div><div class="MuiPaper-root MuiCard-root jss18 MuiPaper-elevation1 MuiPaper-rounded"><div class="jss19"><div class="MuiCardContent-root jss20"><h6 class="MuiTypography-root MuiTypography-subtitle1 MuiTypography-colorTextSecondary">项欣光，南京理工大学计算机科学与工程学院教授、博士生导师。2005，2007和2011年毕业于哈尔滨工业大学计算机科学与技术学院，分别获工学学士学位，工学硕士学位和工学博士学位。项欣光博士一直从事图像/视频处理，视频压缩与通讯，多媒体内容分析与理解等方向的研究工作，发表高水平学术论文100余篇，包括在权威国际期刊（T-IP、T-MM、T-CSVT）和著名国际会议（NeurIPS、DCC、ICASSP）上发表相关工作。曾先后在中科院计算所，北京大学数字媒体所，以及微软亚洲研究院做访问研究。先后承担与参与国家自然科学基金项目（重点、科学仪器、面上）、国家重点研发计划课题、国家高技术研究发展计划（863计划）课题、江苏省自然科学基金项目，高等学校博士学科点专项科研基金等项目。项欣光博士是T-PAMI、T-IP、T-MM等国际杂志的审稿人，以及电气和电子工程师协会(IEEE)，美国计算机协会（ACM），中国计算机学会（CCF）会员。<a href="javascript:void(0)">English Version</a></h6></div><div class="jss22"></div></div></div></div><div><h1 class="MuiTypography-root MuiTypography-h5 MuiTypography-alignLeft" style="padding-bottom:20px;padding-top:20px">论文</h1><li style="padding:10px;color:#000000">Sub-region localized hashing for fine-grained image retrieval. Xinguang Xiang, Yajie Zhang, Lu Jin, Zechao Li, Jinhui Tang. (IEEE Transactions on Image Processing) .第一作者</li><li style="padding:10px;color:#000000">Deep video deblurring using sharpness features from exemplars. Xinguang Xiang, Hao Wei, Jinshan Pan. (IEEE Transactions on Image Processing) .第一作者</li><li style="padding:10px;color:#000000">Alleviating Over-Fitting in Hashing-Based Fine-Grained Image Retrieval: From Causal Feature Learning to Binary-Injected Hash Learning. Xinguang Xiang, Xinhao Ding, Lu Jin, Zechao Li, Jinhui Tang, Ramesh Jain. (Trans. Multi.) .第一作者</li><li style="padding:10px;color:#000000">Self-Guided Image Dehazing Using Progressive Feature Fusion. Haoran Bai, Jinshan Pan, Xinguang Xiang, Jinhui Tang. (IEEE Transactions on Image Processing) .通讯作者</li><li style="padding:10px;color:#000000">基于解耦图神经网络的可解释标签感知推荐算法. 项欣光 杜晓宇. (软件学报) .通讯作者</li><li style="padding:10px;color:#000000">Unabridged adjacent modulation for clothing parsing. Dong Zhang, Chengting Zuo, Qianhao Wu, Liyong Fu, Xinguang Xiang. (Pattern Recognition) .通讯作者</li><li style="padding:10px;color:#000000">Tracking the evolution of overlapping communities in dynamic social networks. Zhixiao Wang, Zechao Li, Guan Yuan, Yunlian Sun, Xiaobin Rui, Xinguang Xiang. (Knowledge-Based Systems) .通讯作者</li><li style="padding:10px;color:#000000">Color face recognition by PCA-like approach. Xinguang Xiang, Jing Yang, Qiuping Chen. (Neurocomputing) .第一作者</li><li style="padding:10px;color:#000000">Packet video error concealment with auto regressive model. Yongbing Zhang, Xinguang Xiang, Debin Zhao, Siwe Ma, Wen Gao. (IEEE Transactions on Circuits and Systems for Video Technology) .其他作者</li><li style="padding:10px;color:#000000">基于交互序列商品相关性建模的图卷积会话推荐. 闫昭, 项欣光, 李泽超. (中国科学：信息科学) .其他作者</li><li style="padding:10px;color:#000000">MAU: A Motion-Aware Unit for Video Prediction and Beyond. Zheng Chang, Xinfeng Zhang, Shanshe Wang, Siwei Ma, Yan Ye, Xiang Xinguang, Wen Gao. (Advances in Neural Information Processing Systems) .其他作者</li><li style="padding:10px;color:#000000">A joint encoder--decoder error control framework for stereoscopic video coding. Xinguang Xiang, Debin Zhao, Qiang Wang, Siwei Ma, Wen Gao. (Journal of Visual Communication and Image Representation) .第一作者</li><h1 class="MuiTypography-root MuiTypography-h5 MuiTypography-alignLeft" style="padding-bottom:20px;padding-top:20px">项目</h1><li style="padding:10px;color:#000000">国家自然科学基金（面上项目） &quot;面向户外成像环境的退化图像与视频复原方法研究&quot;, (No.62272230), 2023-2026, 主持</li><li style="padding:10px;color:#000000">国家自然科学基金（科学仪器基础研究专款） &quot;动态可配置的压缩感知成像系统&quot;, (No.61327013), 2014-2017, 主持</li><li style="padding:10px;color:#000000">国家自然科学基金（青年科学基金项目） &quot;多视点视频编码中容错控制技术研究&quot;, (No.61301106), 2014-2016, 主持</li><li style="padding:10px;color:#000000">江苏省自然科学基金（青年基金项目） &quot;三维视频编码中容错技术研究&quot;, (No.BK2012397), 2012-2015, 主持</li><li style="padding:10px;color:#000000">高等学校博士学科点专项科研基金 &quot;面向容错鲁棒性传输的三维视频编码技术研究&quot;, (No.20123219120024), 2013-2015, 主持</li></div></div></div></div></div></div><div class="jss7"><div class="jss8"><div><p class="MuiTypography-root MuiTypography-body1" style="color:#ffffff">Copyright © 2022 南京理工大学智能媒体分析实验室. All rights reserved.</p></div><div><p class="MuiTypography-root MuiTypography-body1 MuiTypography-gutterBottom" style="color:#ffffff">Theme: ColorMag by ThemeGrill. Powered by WordPress.</p></div></div></div></div></div><script type="text/javascript">window.__routeInfo = JSON.parse("{\"template\":\"__react_static_root__/src/containers/User\",\"sharedHashesByProp\":{},\"data\":{\"userInfo\":{\"id\":\"xiangxinguang\",\"info\":{\"classify\":\"0\",\"status\":1,\"id\":15,\"info\":{\"name\":\"\u9879\u6B23\u5149\",\"Eng_name\":\"Xinguang Xiang\",\"phone\":\"00000000\",\"email\":\"xgxiang@njust.edu.cn\",\"profile\":\"Xinguang Xiang is currently a professor at the Nanjing University of Science and Technology. He received the B.A., M.S. and Ph.D. degrees in computer science from the Department of Computer Science and Technology, Harbin Institute of Technology in 2005, 2007, and 2011, respectively. His current research interests include video processing, image and video coding, multimedia analysis and computer vision.\",\"address\":\"\",\"direction\":\"\u89C6\u9891\u5904\u7406\uFF0C\u538B\u7F29\u4E0E\u901A\u8BAF\uFF0C\u667A\u80FD\u5A92\u4F53\u5206\u6790\u3001\u56FE\u50CF\u5904\u7406\u7B49\u65B9\u5411\",\"avatar\":\"../users/static/avatar/xiangxinguang\",\"account\":\"xiangxinguang\",\"profile_c\":\"\u9879\u6B23\u5149\uFF0C\u5357\u4EAC\u7406\u5DE5\u5927\u5B66\u8BA1\u7B97\u673A\u79D1\u5B66\u4E0E\u5DE5\u7A0B\u5B66\u9662\u6559\u6388\u3001\u535A\u58EB\u751F\u5BFC\u5E08\u30022005\uFF0C2007\u548C2011\u5E74\u6BD5\u4E1A\u4E8E\u54C8\u5C14\u6EE8\u5DE5\u4E1A\u5927\u5B66\u8BA1\u7B97\u673A\u79D1\u5B66\u4E0E\u6280\u672F\u5B66\u9662\uFF0C\u5206\u522B\u83B7\u5DE5\u5B66\u5B66\u58EB\u5B66\u4F4D\uFF0C\u5DE5\u5B66\u7855\u58EB\u5B66\u4F4D\u548C\u5DE5\u5B66\u535A\u58EB\u5B66\u4F4D\u3002\u9879\u6B23\u5149\u535A\u58EB\u4E00\u76F4\u4ECE\u4E8B\u56FE\u50CF/\u89C6\u9891\u5904\u7406\uFF0C\u89C6\u9891\u538B\u7F29\u4E0E\u901A\u8BAF\uFF0C\u591A\u5A92\u4F53\u5185\u5BB9\u5206\u6790\u4E0E\u7406\u89E3\u7B49\u65B9\u5411\u7684\u7814\u7A76\u5DE5\u4F5C\uFF0C\u53D1\u8868\u9AD8\u6C34\u5E73\u5B66\u672F\u8BBA\u6587100\u4F59\u7BC7\uFF0C\u5305\u62EC\u5728\u6743\u5A01\u56FD\u9645\u671F\u520A\uFF08T-IP\u3001T-MM\u3001T-CSVT\uFF09\u548C\u8457\u540D\u56FD\u9645\u4F1A\u8BAE\uFF08NeurIPS\u3001DCC\u3001ICASSP\uFF09\u4E0A\u53D1\u8868\u76F8\u5173\u5DE5\u4F5C\u3002\u66FE\u5148\u540E\u5728\u4E2D\u79D1\u9662\u8BA1\u7B97\u6240\uFF0C\u5317\u4EAC\u5927\u5B66\u6570\u5B57\u5A92\u4F53\u6240\uFF0C\u4EE5\u53CA\u5FAE\u8F6F\u4E9A\u6D32\u7814\u7A76\u9662\u505A\u8BBF\u95EE\u7814\u7A76\u3002\u5148\u540E\u627F\u62C5\u4E0E\u53C2\u4E0E\u56FD\u5BB6\u81EA\u7136\u79D1\u5B66\u57FA\u91D1\u9879\u76EE\uFF08\u91CD\u70B9\u3001\u79D1\u5B66\u4EEA\u5668\u3001\u9762\u4E0A\uFF09\u3001\u56FD\u5BB6\u91CD\u70B9\u7814\u53D1\u8BA1\u5212\u8BFE\u9898\u3001\u56FD\u5BB6\u9AD8\u6280\u672F\u7814\u7A76\u53D1\u5C55\u8BA1\u5212\uFF08863\u8BA1\u5212\uFF09\u8BFE\u9898\u3001\u6C5F\u82CF\u7701\u81EA\u7136\u79D1\u5B66\u57FA\u91D1\u9879\u76EE\uFF0C\u9AD8\u7B49\u5B66\u6821\u535A\u58EB\u5B66\u79D1\u70B9\u4E13\u9879\u79D1\u7814\u57FA\u91D1\u7B49\u9879\u76EE\u3002\u9879\u6B23\u5149\u535A\u58EB\u662FT-PAMI\u3001T-IP\u3001T-MM\u7B49\u56FD\u9645\u6742\u5FD7\u7684\u5BA1\u7A3F\u4EBA\uFF0C\u4EE5\u53CA\u7535\u6C14\u548C\u7535\u5B50\u5DE5\u7A0B\u5E08\u534F\u4F1A(IEEE)\uFF0C\u7F8E\u56FD\u8BA1\u7B97\u673A\u534F\u4F1A\uFF08ACM\uFF09\uFF0C\u4E2D\u56FD\u8BA1\u7B97\u673A\u5B66\u4F1A\uFF08CCF\uFF09\u4F1A\u5458\u3002\",\"job_title\":\"Professor\"},\"journal\":[{\"id\":80,\"name\":\"Sub-region localized hashing for fine-grained image retrieval\",\"author\":\"Xinguang Xiang, Yajie Zhang, Lu Jin, Zechao Li, Jinhui Tang\",\"jn_name\":\"IEEE Transactions on Image Processing\",\"dat\":\"2021\",\"num\":\"\",\"employ\":\"\",\"employ_num\":\"\",\"ccf\":\"\",\"cas\":\"\",\"jcr\":\"\",\"times\":\"\",\"vol\":\"31\",\"no\":\"\",\"page\":\"314-326\",\"DOI\":\"\",\"link\":\"\",\"code_link\":\"\",\"bibtex\":true,\"encd\":\"\",\"code_encd\":\"[]\",\"authors\":[\"\u7B2C\u4E00\u4F5C\u8005\"]},{\"id\":95,\"name\":\"Deep video deblurring using sharpness features from exemplars\",\"author\":\"Xinguang Xiang, Hao Wei, Jinshan Pan\",\"jn_name\":\"IEEE Transactions on Image Processing\",\"dat\":\"2020\",\"num\":\"\",\"employ\":\"\",\"employ_num\":\"\",\"ccf\":\"\",\"cas\":\"\",\"jcr\":\"\",\"times\":\"\",\"vol\":\"29\",\"no\":\"\",\"page\":\"8976-8987\",\"DOI\":\"\",\"link\":\"\",\"code_link\":\"\",\"bibtex\":true,\"encd\":\"\",\"code_encd\":\"[]\",\"authors\":[\"\u7B2C\u4E00\u4F5C\u8005\"]},{\"id\":193,\"name\":\"Alleviating Over-Fitting in Hashing-Based Fine-Grained Image Retrieval: From Causal Feature Learning to Binary-Injected Hash Learning\",\"author\":\"Xinguang Xiang, Xinhao Ding, Lu Jin, Zechao Li, Jinhui Tang, Ramesh Jain\",\"jn_name\":\"Trans. Multi.\",\"dat\":\"2024\",\"num\":\"\",\"employ\":\"\",\"employ_num\":\"\",\"ccf\":\"\",\"cas\":\"\",\"jcr\":\"\",\"times\":\"\",\"vol\":\"26\",\"no\":\"\",\"page\":\"10665\u201310677\",\"DOI\":\"\",\"link\":\"\",\"code_link\":\"\",\"bibtex\":false,\"encd\":\"\",\"code_encd\":\"[]\",\"authors\":[\"\u7B2C\u4E00\u4F5C\u8005\"]},{\"id\":194,\"name\":\"Self-Guided Image Dehazing Using Progressive Feature Fusion\",\"author\":\"Haoran Bai, Jinshan Pan, Xinguang Xiang, Jinhui Tang\",\"jn_name\":\"IEEE Transactions on Image Processing\",\"dat\":\"2022\",\"num\":\"\",\"employ\":\"\",\"employ_num\":\"\",\"ccf\":\"\",\"cas\":\"\",\"jcr\":\"\",\"times\":\"\",\"vol\":\"31\",\"no\":\"\",\"page\":\"1217-1229\",\"DOI\":\"\",\"link\":\"\",\"code_link\":\"\",\"bibtex\":false,\"encd\":\"\",\"code_encd\":\"[]\",\"authors\":[\"\u901A\u8BAF\u4F5C\u8005\"]},{\"id\":195,\"name\":\"\u57FA\u4E8E\u89E3\u8026\u56FE\u795E\u7ECF\u7F51\u7EDC\u7684\u53EF\u89E3\u91CA\u6807\u7B7E\u611F\u77E5\u63A8\u8350\u7B97\u6CD5\",\"author\":\"\u9879\u6B23\u5149 \u675C\u6653\u5B87\",\"jn_name\":\"\u8F6F\u4EF6\u5B66\u62A5\",\"dat\":\"2023\",\"num\":\"\",\"employ\":\"\",\"employ_num\":\"\",\"ccf\":\"\",\"cas\":\"\",\"jcr\":\"\",\"times\":\"\",\"vol\":\"34\",\"no\":\"12\",\"page\":\"5670\",\"DOI\":\"\",\"link\":\"\",\"code_link\":\"\",\"bibtex\":false,\"encd\":\"\",\"code_encd\":\"[]\",\"authors\":[\"\u901A\u8BAF\u4F5C\u8005\"]},{\"id\":89,\"name\":\"Unabridged adjacent modulation for clothing parsing\",\"author\":\"Dong Zhang, Chengting Zuo, Qianhao Wu, Liyong Fu, Xinguang Xiang\",\"jn_name\":\"Pattern Recognition\",\"dat\":\"2022\",\"num\":\"\",\"employ\":\"\",\"employ_num\":\"\",\"ccf\":\"\",\"cas\":\"\",\"jcr\":\"\",\"times\":\"\",\"vol\":\"127\",\"no\":\"\",\"page\":\"108594\",\"DOI\":\"\",\"link\":\"\",\"code_link\":\"\",\"bibtex\":true,\"encd\":\"\",\"code_encd\":\"[]\",\"authors\":[\"\u901A\u8BAF\u4F5C\u8005\"]},{\"id\":96,\"name\":\"Tracking the evolution of overlapping communities in dynamic social networks\",\"author\":\"Zhixiao Wang, Zechao Li, Guan Yuan, Yunlian Sun, Xiaobin Rui, Xinguang Xiang\",\"jn_name\":\"Knowledge-Based Systems\",\"dat\":\"2018\",\"num\":\"\",\"employ\":\"\",\"employ_num\":\"\",\"ccf\":\"\",\"cas\":\"\",\"jcr\":\"\",\"times\":\"\",\"vol\":\"157\",\"no\":\"\",\"page\":\"81-97\",\"DOI\":\"\",\"link\":\"\",\"code_link\":\"\",\"bibtex\":true,\"encd\":\"\",\"code_encd\":\"[]\",\"authors\":[\"\u901A\u8BAF\u4F5C\u8005\"]},{\"id\":98,\"name\":\"Color face recognition by PCA-like approach\",\"author\":\"Xinguang Xiang, Jing Yang, Qiuping Chen\",\"jn_name\":\"Neurocomputing\",\"dat\":\"2015\",\"num\":\"\",\"employ\":\"\",\"employ_num\":\"\",\"ccf\":\"\",\"cas\":\"\",\"jcr\":\"\",\"times\":\"\",\"vol\":\"152\",\"no\":\"\",\"page\":\"231-235\",\"DOI\":\"\",\"link\":\"\",\"code_link\":\"\",\"bibtex\":true,\"encd\":\"\",\"code_encd\":\"[]\",\"authors\":[\"\u7B2C\u4E00\u4F5C\u8005\"]},{\"id\":99,\"name\":\"Packet video error concealment with auto regressive model\",\"author\":\"Yongbing Zhang, Xinguang Xiang, Debin Zhao, Siwe Ma, Wen Gao\",\"jn_name\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"dat\":\"2011\",\"num\":\"\",\"employ\":\"\",\"employ_num\":\"\",\"ccf\":\"\",\"cas\":\"\",\"jcr\":\"\",\"times\":\"\",\"vol\":\"22\",\"no\":\"1\",\"page\":\"12-27\",\"DOI\":\"\",\"link\":\"\",\"code_link\":\"\",\"bibtex\":true,\"encd\":\"\",\"code_encd\":\"[]\",\"authors\":[\"\u5176\u4ED6\u4F5C\u8005\"]},{\"id\":93,\"name\":\"\u57FA\u4E8E\u4EA4\u4E92\u5E8F\u5217\u5546\u54C1\u76F8\u5173\u6027\u5EFA\u6A21\u7684\u56FE\u5377\u79EF\u4F1A\u8BDD\u63A8\u8350\",\"author\":\"\u95EB\u662D, \u9879\u6B23\u5149, \u674E\u6CFD\u8D85\",\"jn_name\":\"\u4E2D\u56FD\u79D1\u5B66\uFF1A\u4FE1\u606F\u79D1\u5B66\",\"dat\":\"2022\",\"num\":\"\",\"employ\":\"\",\"employ_num\":\"\",\"ccf\":\"\",\"cas\":\"\",\"jcr\":\"\",\"times\":\"\",\"vol\":\"\",\"no\":\"052-006\",\"page\":\"1069-1082\",\"DOI\":\"\",\"link\":\"\",\"code_link\":\"\",\"bibtex\":true,\"encd\":\"\",\"code_encd\":\"[]\",\"authors\":[\"\u5176\u4ED6\u4F5C\u8005\"]},{\"id\":121,\"name\":\"MAU: A Motion-Aware Unit for Video Prediction and Beyond\",\"author\":\"Zheng Chang, Xinfeng Zhang, Shanshe Wang, Siwei Ma, Yan Ye, Xiang Xinguang, Wen Gao\",\"jn_name\":\"Advances in Neural Information Processing Systems\",\"dat\":\"2021\",\"num\":\"\",\"employ\":\"\",\"employ_num\":\"\",\"ccf\":\"\",\"cas\":\"\",\"jcr\":\"\",\"times\":\"\",\"vol\":\"34\",\"no\":\"\",\"page\":\"26950-26962\",\"DOI\":\"\",\"link\":\"\",\"code_link\":\"\",\"bibtex\":true,\"encd\":\"\",\"code_encd\":\"[]\",\"authors\":[\"\u5176\u4ED6\u4F5C\u8005\"]},{\"id\":100,\"name\":\"A joint encoder--decoder error control framework for stereoscopic video coding\",\"author\":\"Xinguang Xiang, Debin Zhao, Qiang Wang, Siwei Ma, Wen Gao\",\"jn_name\":\"Journal of Visual Communication and Image Representation\",\"dat\":\"2010\",\"num\":\"\",\"employ\":\"\",\"employ_num\":\"\",\"ccf\":\"\",\"cas\":\"\",\"jcr\":\"\",\"times\":\"\",\"vol\":\"21\",\"no\":\"8\",\"page\":\"975-985\",\"DOI\":\"\",\"link\":\"\",\"code_link\":\"\",\"bibtex\":true,\"encd\":\"\",\"code_encd\":\"[]\",\"authors\":[\"\u7B2C\u4E00\u4F5C\u8005\"]}],\"competition\":[],\"project\":[{\"id\":68,\"name\":\"\u9762\u5411\u6237\u5916\u6210\u50CF\u73AF\u5883\u7684\u9000\u5316\u56FE\u50CF\u4E0E\u89C6\u9891\u590D\u539F\u65B9\u6CD5\u7814\u7A76\",\"principal\":\"\u9879\u6B23\u5149\",\"level\":\"\",\"start_time\":\"2023-01-01\",\"deadline\":\"2026-12-01\",\"cost\":\"54\",\"prog_num\":\"62272230\",\"pro_source\":\"\u56FD\u5BB6\u81EA\u7136\u79D1\u5B66\u57FA\u91D1\uFF08\u9762\u4E0A\u9879\u76EE\uFF09\",\"file\":\"[]\",\"member\":\"\",\"fund\":\"\",\"role\":\"\u4E3B\u6301\"},{\"id\":82,\"name\":\"\u52A8\u6001\u53EF\u914D\u7F6E\u7684\u538B\u7F29\u611F\u77E5\u6210\u50CF\u7CFB\u7EDF\",\"principal\":\"\u9879\u6B23\u5149\",\"level\":\"\u7B2C\u4E94\u7C7B\",\"start_time\":\"2014-01-01\",\"deadline\":\"2017-12-01\",\"cost\":\"25\",\"prog_num\":\"61327013\",\"pro_source\":\"\u56FD\u5BB6\u81EA\u7136\u79D1\u5B66\u57FA\u91D1\uFF08\u79D1\u5B66\u4EEA\u5668\u57FA\u7840\u7814\u7A76\u4E13\u6B3E\uFF09\",\"file\":\"[]\",\"member\":\"\",\"fund\":\"\",\"role\":\"\u4E3B\u6301\"},{\"id\":83,\"name\":\"\u591A\u89C6\u70B9\u89C6\u9891\u7F16\u7801\u4E2D\u5BB9\u9519\u63A7\u5236\u6280\u672F\u7814\u7A76\",\"principal\":\"\u9879\u6B23\u5149\",\"level\":\"\u7B2C\u4E09\u7C7B\",\"start_time\":\"2014-01-01\",\"deadline\":\"2016-12-01\",\"cost\":\"28\",\"prog_num\":\"61301106\",\"pro_source\":\"\u56FD\u5BB6\u81EA\u7136\u79D1\u5B66\u57FA\u91D1\uFF08\u9752\u5E74\u79D1\u5B66\u57FA\u91D1\u9879\u76EE\uFF09\",\"file\":\"[]\",\"member\":\"\",\"fund\":\"\",\"role\":\"\u4E3B\u6301\"},{\"id\":84,\"name\":\"\u4E09\u7EF4\u89C6\u9891\u7F16\u7801\u4E2D\u5BB9\u9519\u6280\u672F\u7814\u7A76\",\"principal\":\"\u9879\u6B23\u5149\",\"level\":\"\u7B2C\u56DB\u7C7B\",\"start_time\":\"2012-07-01\",\"deadline\":\"2015-06-01\",\"cost\":\"20\",\"prog_num\":\"BK2012397\",\"pro_source\":\"\u6C5F\u82CF\u7701\u81EA\u7136\u79D1\u5B66\u57FA\u91D1\uFF08\u9752\u5E74\u57FA\u91D1\u9879\u76EE\uFF09\",\"file\":\"[]\",\"member\":\"\",\"fund\":\"\",\"role\":\"\u4E3B\u6301\"},{\"id\":85,\"name\":\"\u9762\u5411\u5BB9\u9519\u9C81\u68D2\u6027\u4F20\u8F93\u7684\u4E09\u7EF4\u89C6\u9891\u7F16\u7801\u6280\u672F\u7814\u7A76\",\"principal\":\"\u9879\u6B23\u5149\",\"level\":\"\u7B2C\u4E94\u7C7B\",\"start_time\":\"2013-01-01\",\"deadline\":\"2015-12-01\",\"cost\":\"4\",\"prog_num\":\"20123219120024\",\"pro_source\":\"\u9AD8\u7B49\u5B66\u6821\u535A\u58EB\u5B66\u79D1\u70B9\u4E13\u9879\u79D1\u7814\u57FA\u91D1\",\"file\":\"[]\",\"member\":\"\",\"fund\":\"\",\"role\":\"\u4E3B\u6301\"}],\"honor\":[],\"course\":[]}}},\"path\":\"people/user/xiangxinguang\",\"sharedData\":{},\"siteData\":{}}");</script><script defer="" type="text/javascript" src="/templates/styles.e9e5bf98.js"></script><script defer="" type="text/javascript" src="/templates/vendors~main.8ca25124.js"></script><script defer="" type="text/javascript" src="/main.7753e46a.js"></script></body></html>